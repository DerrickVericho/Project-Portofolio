{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üê∂ End-to-end Multi-class Dog Breed Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Problem\n",
    "\n",
    "- Identifying the breed of a dog given an image of a dog. \n",
    "- When I'm sitting at the cafe and I take a photo of a dog, I want to know what breed of dog it is.\n",
    "\n",
    "2. Data\n",
    "\n",
    "- The data we're using is from Kaggle's dog breed identification competition.\n",
    "- Dataset: https://www.kaggle.com/c/dog-breed-identification/data\n",
    "\n",
    "3. Evaluation\n",
    "- The evaluation is a file with prediction probabilities for each dog breed of each test image.\n",
    "- Evaluation: https://www.kaggle.com/c/dog-breed-identification/overview/evaluation\n",
    "\n",
    "4. Features\n",
    "- Some information about the data:\n",
    "    1. We're dealing with images (unstructured data) so it's probably best we use deep learning/transfer learning.\n",
    "    2. There are 120 breeds of dogs (this means there are 120 different classes).\n",
    "    3. There are around 10,000+ images in the training set (these images have labels).\n",
    "    4. There are around 10,000+ images in the test set (these images have no labels, because we'll want to predict them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Tensorflow & Tensorflow hub version and make sure GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.8' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/asus/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(\"Tensorflow_hub version: \", hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Libraries & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "labels_csv = pd.read_csv(\"labels.csv\")\n",
    "labels_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_csv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_csv['breed'].value_counts().plot.bar(figsize =(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_csv['breed'].value_counts().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try look an example of dog picture\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(\"train/000bec180eb18c7604dcecc8fe0dba07.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get images and their label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_id = [\"train/\" + fname + \".jpg\" for fname in labels_csv['id']]\n",
    "label_id[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if len(os.listdir(\"train/\")) == len(label_id):\n",
    "    print(\"We're good to go\")\n",
    "else:\n",
    "    print(\"Data don't match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_csv['breed'].to_numpy()\n",
    "unique_breeds = np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_labels = [unique_breeds == labels for labels in labels]\n",
    "len(boolean_labels)\n",
    "boolean_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = label_id\n",
    "y = boolean_labels\n",
    "\n",
    "num_images = 1000\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X[:num_images], y[:num_images], test_size=0.2, random_state=42)\n",
    "\n",
    "len(X_train), len(y_train), len(X_val), len(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To preprocess image we need to write a function which does:\n",
    "1. Take an image filepath as input\n",
    "2. Use tensorflow to read the file and save it to a variable, `image`\n",
    "3. Turn out `image` (a jpg) into Tensors\n",
    "4. Normalize our image (convert colour channel from 0-255 to 0-1)\n",
    "5. Resize the `image` to be a shape of (224,224)\n",
    "6. Return the modified `image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imread\n",
    "image = imread(label_id[50])\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.io import read_file # type: ignore\n",
    "from tensorflow.image import decode_jpeg, convert_image_dtype, resize # type: ignore\n",
    "\n",
    "image_size = 224\n",
    "\n",
    "# Image resizing function\n",
    "def image_resizing(path):\n",
    "\n",
    "    # Firstly we read the image path in byte (raw data)\n",
    "    # Turn the image into numerical tensors with 3 colours channel to be proceed by TF\n",
    "    # Convert image dtype from uint8(0-255) to float(0-1) to helps model performance\n",
    "    # Change the image size into [224,224] for consistant size\n",
    "\n",
    "    image = read_file(path)\n",
    "    image = decode_jpeg(image)\n",
    "    image = convert_image_dtype(image, tf.float32)\n",
    "    image = resize(image, size=[image_size, image_size]) #method=(bilinear) -nearest, bicubic etc\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning Data Into Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_label(path, label):\n",
    "    image = image_resizing(path)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "def create_data_batch(X, y=None, batch_size = batch_size, valid_data=False, test_data=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Create Data batches \n",
    "    Training data: we do shuffle and input x & y\n",
    "    Validation data: we dont shuffle but input x & y, \n",
    "    Test data: we input x data (no labels)\n",
    "    \"\"\"\n",
    "\n",
    "    # For test data\n",
    "    if test_data:\n",
    "        print(\"Creating Test Data....\")\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(X)))\n",
    "        data_batch = data.map(image_resizing).batch(batch_size)\n",
    "        return data_batch\n",
    "    \n",
    "    elif valid_data:\n",
    "        print(\"Creating Validation Data....\")\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n",
    "        data_batch = data.map(get_image_label).batch(batch_size)\n",
    "        return data_batch\n",
    "    \n",
    "    else:\n",
    "        print(\"Creating Train Data....\")\n",
    "        data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n",
    "        data = data.shuffle(buffer_size=len(X))\n",
    "        data_batch = data.map(get_image_label).batch(batch_size)\n",
    "        return data_batch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training and Validation data batches\n",
    "\n",
    "train_data = create_data_batch(X_train, y_train)\n",
    "val_data = create_data_batch(X_val, y_val, valid_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.element_spec, val_data.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing out train & valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_25_images(images, label):\n",
    "    plt.figure(figsize=(10,15))\n",
    "\n",
    "    for i in range(25):\n",
    "        ax = plt.subplot(5,5, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(unique_breeds[label[i].argmax()])\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_data.as_numpy_iterator())\n",
    "show_25_images(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we build a model, there are a few things we need to define:\n",
    "\n",
    "- The input shape (images, in the form of Tensors) to our model.\n",
    "- The output shape (image labels, in the form of Tensors) of our model.\n",
    "- The URL of the model we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setp input shape\n",
    "input_shape = [None, image_size, image_size, 3] #batch, height, width, channel\n",
    "\n",
    "# Setup output shape\n",
    "output_shape = len(unique_breeds)\n",
    "\n",
    "# Setup model url\n",
    "MODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Dense # type: ignore\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy # type: ignore\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore\n",
    "\n",
    "def create_model(input_shape=input_shape, output_shape=output_shape, model_url=MODEL_URL):\n",
    "    print(\"Building Model with: \", MODEL_URL)\n",
    "\n",
    "    model = Sequential([\n",
    "        hub.KerasLayer(model_url), # Layer 1 (input layer) & hidden layer inside the URL\n",
    "        Dense(units=output_shape, activation='softmax') # Output Layer\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=CategoricalCrossentropy(),\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.build(input_shape)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks are helper functions a model can use during training to do things such as save a models progress, check a models progress or stop training early if a model stops improving.\n",
    "\n",
    "We will use 2 Callbacks: TensorBoard and EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up a TensorBoard callback and view TensorBoard in a notebook, we need to do three things:\n",
    "1. Load the TensorBoard notebook extension.\n",
    "2. Create a TensorBoard callback which is able to save logs to a directory and pass it to our model's `fit()` function.\n",
    "3. Visualize the our models training logs using the `%tensorboard` magic function (we'll do this later on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# from tensorflow.keras.callbacks import TensorBoard \n",
    "\n",
    "# Create a function to build a tensorboard callback\n",
    "def create_tensorboard():\n",
    "\n",
    "    # Create a log directory for storing tensorboard logs\n",
    "    logdir = os.path.join(\"./logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "    return tf.keras.callbacks.TensorBoard(logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early Stopping helps prevent overfitting by stopping a model when a certain evaluation metric stops improving. If a model trains for too long, it can do so well at finding patterns in a certain dataset that it's not able to use those patterns on another dataset it hasn't seen before (doesn't generalize).\n",
    "\n",
    "It's basically like saying to our model, \"keep finding patterns until the quality of those patterns starts to go down.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf.keras.callbacks import EarlyStopping \n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model is only going to be trained on 1000 images. Trained on 800 images and then validated on 200 images, meaning 1000 images total or about 10% of the total data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check GPU Available\n",
    "print(\"YES\" if tf.config.list_physical_devices('GPU') else \"Not Available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple function which trains a model. The function will:\n",
    "* Create a model using `create_model()`.\n",
    "* Setup a TensorBoard callback using `create_tensorboard_callback()` (we do this here so it creates a log directory of the current date and time).\n",
    "* Call the `fit()` function on our model passing it the training data, validatation data, number of epochs to train for and the callbacks we'd like to use.\n",
    "* Return the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "# Build train function to train and return a trained model\n",
    "def train_model():\n",
    "\n",
    "    # Create a model\n",
    "    model = create_model()\n",
    "    \n",
    "    # Create a tensorboard\n",
    "    tensorboard = create_tensorboard()\n",
    "\n",
    "    # Fit the model to the data passing it the callbacks we created\n",
    "    model.fit(x=train_data,\n",
    "              epochs=num_epochs,\n",
    "              validation_data=val_data,\n",
    "              validation_freq=1, #Check validation metrics every epochs\n",
    "              callbacks=[tensorboard, early_stopping])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to data\n",
    "\n",
    "# Train 25 step = 800(train_data) / 32(batch), Val 7 step = 100(val_data) / 32(batch)\n",
    "model = train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** It looks like our model might be overfitting (getting far better results on the training set than the validation set), what are some ways to prevent model overfitting in a deep learning model?.\n",
    "\n",
    "**Note:** Overfitting to begin with is a good thing. It means our model is learning something."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making and Evaluating predictions using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation data\n",
    "\n",
    "predictions = model.predict(val_data, verbose = 1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)\n",
    "print(len(y_val), len(unique_breeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First predictions\n",
    "\n",
    "index = 0\n",
    "#print(predictions[index])\n",
    "print(f\"Max value (probability of prediction): {np.max(predictions[index])}\") # the max probability value predicted by the model\n",
    "print(f\"Sum: {np.sum(predictions[index])}\") # because we used softmax activation in our model, this will be close to 1\n",
    "print(f\"Max index: {np.argmax(predictions[index])}\") # the index of where the max value in predictions[index] occurs\n",
    "print(f\"Predicted label: {unique_breeds[np.argmax(predictions[index])]}\") # the predicted label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having this information is great but it would be even better if we could compare a prediction to its true label and original image.\n",
    "\n",
    "To help us, let's first build a little function to convert prediction probabilities into predicted labels.\n",
    "\n",
    "**Note:** Prediction probabilities are also known as confidence levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create get label Function\n",
    "def get_pred_label(predictions_proba):\n",
    "    label = np.argmax(predictions_proba)\n",
    "    return unique_breeds[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our validation data is in batch form, we'll have to unbatch with (using `unbatch()`) and then turn it into an iterator using `as_numpy_iterator()` to make a predictions on validation images and then compare those to the validations label (truth labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unbatch Function\n",
    "\n",
    "def unbatch_data(data):\n",
    "\n",
    "    \"\"\"\n",
    "    Take a batch data of(images, labels) tensors and return seperate array of image and label\n",
    "    \"\"\"\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for image, label in data.unbatch().as_numpy_iterator():\n",
    "        images.append(image)\n",
    "        labels.append(unique_breeds[np.argmax(label)])\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "val_images, val_label = unbatch_data(val_data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got ways to get:\n",
    "* Prediction labels\n",
    "* Validation labels (truth labels)\n",
    "* Validation images\n",
    "\n",
    "Let's make some functions to make these all a bit more visualize.\n",
    "\n",
    "More specifically, we want to be able to view an image, its predicted label and its actual label (true label).\n",
    "\n",
    "The first function we'll create will:\n",
    "* Take an array of prediction probabilities, an array of truth labels, an array of images and an integer (index of sample).\n",
    "* Convert the prediction probabilities to a predicted label.\n",
    "* Plot the predicted label, its predicted probability, the truth label and target image on a single plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_label(predict_proba, labels, images, n=1):\n",
    "\n",
    "    pred_prob, true_label, image = predict_proba[n], labels[n], images[n]\n",
    "\n",
    "    pred_label = get_pred_label(pred_prob)\n",
    "    plt.imshow(image)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    if pred_label == true_label:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.title(f\"Predicted : {pred_label} {np.max(pred_prob)*100:.2f}% \\nActual label : {true_label}\", color = color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label(predictions, val_label, val_images, n = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're working with a multi-class problem (120 different dog breeds), it would also be good to see what other guesses our model is predicting.\n",
    "\n",
    "Let's build a function to demonstrate. The function will be:\n",
    "* Take an input of a prediction probabilities array, a ground truth labels array and an integer.\n",
    "* Find the predicted label using `get_pred_label()`.\n",
    "* Find the top 10:\n",
    "  * Prediction probabilities indexes\n",
    "  * Prediction probabilities values\n",
    "  * Prediction labels\n",
    "* Plot the top 10 prediction probability values and labels, coloring the true label green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_pred(predict_proba, labels, n=1):\n",
    "    \"\"\"\n",
    "    Plot the top 10 prediction confidence along with the truth label for sample n\n",
    "    \"\"\"\n",
    "\n",
    "    pred_prob, true_label = predict_proba[n], labels[n]\n",
    "\n",
    "    # Find the top 10 index\n",
    "    top_10_index = pred_prob.argsort()[-10:][::-1]\n",
    "    # Find top 10 predictions value\n",
    "    top_10_values = pred_prob[top_10_index]\n",
    "    # Find top 10 predictions labels\n",
    "    top_10_label = unique_breeds[top_10_index]\n",
    "\n",
    "    # Set up plot\n",
    "    top_plot = plt.bar(np.arange(len(top_10_label)),\n",
    "                       top_10_values, color='grey')\n",
    "    plt.xticks(np.arange(len(top_10_label)), labels = top_10_label, rotation = 'vertical')\n",
    "    \n",
    "    # Change true label's bar into green\n",
    "    if np.isin(true_label, top_10_label):\n",
    "        top_plot[np.argmax(top_10_label == true_label)].set_color('green')\n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Green labels is the true label, along with the probabilities as y axis\n",
    "\n",
    "plot_top_pred(predictions, val_label, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create a function to visualize a few of our predictions and evaluate our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_some_pred(num_row, num_col):\n",
    "    num_images = num_row * num_col\n",
    "\n",
    "    plt.figure(figsize=(5*2*num_col, 5*num_row))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(num_row, 2*num_col, 2*i+1)\n",
    "        # def plot_label(predict_proba, labels, images, n=1)\n",
    "        plot_label(predictions, val_label, val_images, n=i)\n",
    "\n",
    "        plt.subplot(num_row, 2*num_col, 2*i+2)\n",
    "        # def plot_top_pred(predict_proba, labels, n=1)\n",
    "        plot_top_pred(predictions, val_label, n=i)\n",
    "\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_some_pred(4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and reloading trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to save model\n",
    "\n",
    "def save_model(model, suffix=None):\n",
    "    \"\"\" \n",
    "    Save a given model in models directory and appends a suffix\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a model directory path with current time\n",
    "    modeldir = os.path.join(\"./models\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    model_path = modeldir + \"-\" + suffix + \".h5\" #save format of our model\n",
    "    print(f\"Saving model to: {model_path}...\")\n",
    "    model.save(model_path)\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to load a trained model\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\" \n",
    "    Loads a saved model from a specified path.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Loading saved model from: {model_path}..\")\n",
    "    model = tf.keras.models.load_model(model_path, custom_objects={\"KerasLayer\": hub.KerasLayer})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, suffix='1000-images-mobilenetv2-Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_1000_image_model = load_model(\"./models/20250221-010534-1000-images-mobilenetv2-Adam.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the pre-saved model\n",
    "model.evaluate(val_data)\n",
    "\n",
    "# Evaluate the loaded model\n",
    "load_1000_image_model.evaluate(val_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to trainin a big dog model (Full data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data batch with the full data set\n",
    "\n",
    "full_data = create_data_batch(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model for full model\n",
    "\n",
    "full_model = create_model()\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a full model callback\n",
    "full_model_tensorboard = create_tensorboard()\n",
    "\n",
    "# No validation set when training on all data, so we can't monitor the validation accuracy\n",
    "full_model_earlystopping = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.fit(x=full_data, \n",
    "               epochs=num_epochs,\n",
    "               callbacks=[full_model_tensorboard, full_model_earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(full_model, suffix=\"full-image-set-mobilenetv2-Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_full_model = load_model(\"./models/20250221-013445-full-image-set-mobilenetv2-Adam.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making prediction on test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our model has been trained on images in the form of Tensor batches, to make predictions on the test data, we'll have to get it into the same format.\n",
    "\n",
    "Luckily we created `create_data_batches()` earlier which can take a list of filenames as input and convert them into Tensor batches.\n",
    "\n",
    "To make predictions on the test data, we'll:\n",
    "* Get the test image filenames.\n",
    "* Convert the filenames into test data batches using `create_data_batches()` and setting the `test_data` parameter to `True` (since there are no labels with the test images).\n",
    "* Make a predictions array by passing the test data batches to the `predict()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"./test/\"\n",
    "test_filenames = [test_path + fname for fname in os.listdir(test_path)]\n",
    "test_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = create_data_batch(test_filenames, test_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data batch using the loaded full model\n",
    "test_predictions = load_full_model.predict(test_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"preds_data.csv\", test_predictions, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = np.loadtxt(\"preds_data.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing test dataset for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at Kaggle sample submit, we wants our models prediction probability outputs in a DataFrame with an ID and a column for each dog breed\n",
    "To do so, we'll:\n",
    "- Create a pandas DataFrame with an ID columns as well as columns for each fog breed\n",
    "- Add data to the ID column by extracting test image ID's from filepath\n",
    "- Add prediction probabilities of each dog breed columns\n",
    "- Export the DataFrame as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame\n",
    "\n",
    "pred_df = pd.DataFrame(columns=['id'] + list(unique_breeds))\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = [os.path.splitext(path)[0] for path in os.listdir(test_path)]\n",
    "pred_df['id'] = test_ids\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[list(unique_breeds)] = test_predictions\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"full_model_prediction.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
